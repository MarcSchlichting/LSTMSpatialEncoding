# LSTM-Based Spatial Encoding: Explainable Path Planning for Time-Variant Multi-Agent Systems 
This repository contains the source code used for the LSTM-based multi-agent path planning method described in *LSTM-Based Spatial Encoding: Explainable Path Planning for Time-Variant Multi-Agent Systems* (Schlichting et al., 2021).
The code can be used as starting point for other multi-agent environments (exchanging the gym environment), following ideas outlined in the paper regarding saftey guarantees, 
or using the code for own experiments. The implementation is based on Open AI's Gym and PyTorch. The files along descriptions how to use them will be uploaded in time for the SciTech 2021 Conference.


The paper can be found using this [link](https://arc.aiaa.org/doi/10.2514/6.2021-1860). In case you use this work for your own research, please cite as:

```
@inproceedings{Schlichting2021,
author = {Marc R. Schlichting and Stefan Notter and Walter Fichter},
title = {LSTM-Based Spatial Encoding: Explainable Path Planning for Time-Variant Multi-Agent Systems},
booktitle = {AIAA Scitech 2021 Forum},
month = {Jan},
year = {2021},
doi = {10.2514/6.2021-1860},
URL = {https://arc.aiaa.org/doi/abs/10.2514/6.2021-1860},
}
```
